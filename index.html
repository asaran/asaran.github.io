<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akanksha Saran</title>
  
  <!--<meta name="author" content="Akanksha Saran">-->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ms-icon.png"> 

  <style>
    :root {
      --container: 800px; /* smaller container for bio and news*/
      --container-wide: 960px; /* bigger container for research*/
    }

    .container {
      max-width: var(--container);
    }

    .container-wide {
      max-width: var(--container-wide);
    }
  </style>
</head>

<body>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table class="container" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akanksha Saran</name>
              </p>
              <p> I am a Postdoctoral Researcher in the <a href="https://www.microsoft.com/en-us/research/theme/reinforcement-learning-group/">Reinforcement Learning Group</a> at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-york/">Microsoft Research NYC</a> where I think about research problems related to human-interactive learning and sequential decision making. I graduated with a PhD in Computer Science from the <a href="https://www.cs.utexas.edu/">University of Texas at Austin</a> where I was advised by <a href="https://www.cs.utexas.edu/~sniekum/">Prof. Scott Niekum</a>. 
                My PhD dissertation characterized intentions of human teachers via multimodal signals such as their visual attention and speech during demonstrations provided to robots or simulated agents, to inform the design of novel learning from demonstration methods.
                <!-- focused on leveraging multimodal cues of human teachers demonstrating tasks to robots for enhanced robot learning from demonstration (LfD). My research  -->
              </p>
              <p>Before starting my graduate education at UT Austin, I worked for a short while as a Research Associate at the <a href="https://www.ri.cmu.edu/">Robotics Institute, Carnegie Mellon University</a> (CMU). Prior to that, I completed my MS in Robotics from CMU where, along with a team of computer vision, medical and design experts, I worked on developing a prototype for a <a href="https://smartrehab.vtc.vt.edu" >home-based stroke rehabilitation system</a>. Before pursuing graduate studies, I completed my undergraduate degree in Computer Science and Engineering from the <a href="https://alumni.iitj.ac.in/">Indian Institute of Technology, Jodhpur</a> in India.
              </p>
              <p style="text-align:center">
                <a href="mailto:akanksha.saran@microsoft.com">Email</a> &nbsp/&nbsp
                <!--<a href="">Bio</a> &nbsp/&nbsp-->
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=zZhWSQ0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/asaran/">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akanksha-saran/">LinkedIn</a> 
                <!-- <a href="https://twitter.com/AkankshaSaran">Twitter</a>  -->
                
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/akanksha4.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/akanksha4.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <hr class="container"/>

        <table class="container" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr><td>
            <heading>&nbsp;&nbsp;News</heading>
            <ul>
            <li> New preprint on <a href="https://arxiv.org/abs/2202.03481">A Ranking Game for Imitation Learning</a>.</li>
            <li> I moved to New York City and started my postdoc at MSR NYC!</li>
            <li> Invited as a panelist for the <a href="https://twitter.com/iitjodhpur/status/1466732355280801794">2021 Undergraduate Orientation</a> at my alma mater <a href="https://iitj.ac.in/">IIT Jodhpur</a>.</li>
            <li> Defended my PhD dissertation on Leveraging Multimodal Human Cues for Enhanced Robot Learning from Demonstration!</li>
            <li> Invited talk at <a href="https://research.google">Google Research</a>.</li> 
            <li> Invited talk at <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a>.</li>
            <li> Invited talk at <a href="https://www.research.ibm.com/labs/watson/">IBM Research</a>.</li>
            <li> Invited talk at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>.</li>
            <li> Presented our work on <a href="https://arxiv.org/abs/2002.12500">Efficiently Guiding Imitation Learning Agents with Human Gaze</a> during the Humans and AI session at <a href="https://aamas2021.soton.ac.uk/">AAMAS 2021</a>.</li>
            <!--<li> Invited talk at the <a href="https://sites.google.com/view/realworldhri-workshop/hri21/speakers-schedules?authuser=0">Workshop on Solutions for Socially Intelligent HRI in Real-World Scenarios</a> at <a href="https://humanrobotinteraction.org/2021/">HRI 2021</a>.</li>-->
            <!--<li> I served as a Program Chair for the <a href="http://www.hripioneers.info/hri21/program_speakers.html">HRI Pioneers workshop</a> at <a href="https://humanrobotinteraction.org/2021/">HRI 2021</a>.</li>-->
            <!--<a href="javascript:toggleblock('news')">---- show more ----</a>
            <div id="news" style="display:none">
            <li> Co-organized the <a href="https://futurecv.github.io/" target="_blank">"Computer Vision After 5 years"</a> workshop at CVPR'19.</li>
            <li> Co-organized the <a href="https://tarl2019.github.io/" target="_blank">Task Agnostic Reinforcement Learning</a> workshop at ICLR'19.</li>
            -->
          </div>
            <!-- <li> Undergrad <a href="#JPM15">paper</a> related to predicting <a href="http://www.huffingtonpost.co.uk/2015/02/23/microsoft-oscar-predictio_n_6735122.html">Oscars</a> published at <a href="http://ubplj.org/index.php/jpm/article/view/1048">JPM</a>. See <a href="#oscarPred">live predictions</a>.</li> -->
            </ul>
          </td></tr>
        </table>


        <hr class="container-wide"/>

        <table class="container" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>

            </td>
          </tr>
        </tbody></table>
        <style>

        /* image style format*/  
        .research-table img {
          display: block;
          max-width: 100%;
          height: auto;
          margin: 0 auto;  /*center align*/
          /* margin-left: auto; */ /*right align*/
        }
        </style>
        <table class="research-table container-wide"  style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/rank-game.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://arxiv.org/abs/2202.03481" id="rank-game">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>A Ranking Game for Imitation Learning</papertitle></a><br>
              Harshit Sikchi, <b>Akanksha Saran</b>, Wonjoon Goo, Scott Niekum<br>
              </p>
        
              <div class="paper" id="rank-game">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="https://arxiv.org/pdf/2202.03481.pdf">pdf</a> 
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <!-- <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> | -->
              <!-- <a href="https://drive.google.com/file/d/1bvfnkqFGF8O39yaF1QOcvhrOx2CpZyxX/view?usp=sharing">slides</a> |
              <a href="phttps://drive.google.com/file/d/1tMnPpqOTG7Jxy34ARQVjAJtSArqLTRw6/view?usp=sharing">spotlight</a> |
              <a href="https://drive.google.com/file/d/1tq07PhWvUAN1-GyGlPh-j9QBGT_gg2tr/view?usp=sharing">demo video</a> |
              <a href="https://techxplore.com/news/2020-03-imitation-algorithms-human.html">media</a> -->
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Treating imitation learning as a two-player ranking game between a policy and a reward function can solve previously unsolvable tasks in the
                Learning from Observation (LfO) setting.</p>
            </td>
          </tr> 


          <tr>
            <!--Update the width:30% and width:70% for text and images to the required proportions-->
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div>
                <img src="images/aux_airl.png" />
              </div>
            </td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="papers/aux_airl.pdf" id="ICMLW21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Aux-AIRL: End-to-End Self-Supervised Reward Learning for Extrapolating beyond Suboptimal Demonstrations</papertitle></a><br>
              Yuchen Cui, Bo Liu, <b>Akanksha Saran</b>, Stephen Giguere, Peter Stone, Scott Niekum<br>
              Short version: Workshop on Self-Supervised Learning for Reasoning <br>and Perception, ICML 2021
              <!-- <b>(Best Cognitive Robotics Paper Award Finalist)</b> -->
              </a>
              </p>
        
              <div class="paper" id="icra21">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="papers/aux_airl.pdf">pdf</a> |
              <a href="https://drive.google.com/file/d/1mzCN9X3g4zB6icu_TOc8qKxZHwNTvvEx/view?usp=sharing">poster</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>An end-to-end self-supervised reward learning method that extrapolates beyond suboptimal demonstrations.</p>
            </td>
          </tr> 

         

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/cgl2.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://arxiv.org/abs/2002.12500" id="AAMAS21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Efficiently Guiding Imitation Learning Agents with Human Gaze</papertitle></a><br>
              <b>Akanksha Saran</b>, Ruohan Zhang, Elaine Schaertl Short, Scott Niekum<br>
              Short version: Workshop on Reinforcement Learning in Games, AAAI 2020
              <br>Full version: AAMAS 2021
              </p>
        
              <div class="paper" id="aamas21">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="https://arxiv.org/pdf/2002.12500.pdf">pdf</a> |
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <a href="https://github.com/asaran/IL-CGL">code</a> |
              <a href="https://drive.google.com/file/d/1bvfnkqFGF8O39yaF1QOcvhrOx2CpZyxX/view?usp=sharing">slides</a> |
              <a href="https://drive.google.com/file/d/1tMnPpqOTG7Jxy34ARQVjAJtSArqLTRw6/view?usp=sharing">spotlight</a> |
              <!-- <a href="https://drive.google.com/file/d/1tq07PhWvUAN1-GyGlPh-j9QBGT_gg2tr/view?usp=sharing">demo video</a> | -->
              <a href="https://techxplore.com/news/2020-03-imitation-algorithms-human.html">media</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <!-- <p>Human demonstrators' gaze used as a cue to inform which visual elements of the scene are important for decision-making.</p> -->
              <p>Human demonstrators' overt visual attention can be used as a supervisory signal to guide imitation learning agents during training, such that they <i>at least</i> attend to visual features considered important by the demonstrator.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/survey2.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://www.ijcai.org/Proceedings/2020/0689.pdf" id="IJCAI20">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Human Gaze Assisted Artificial Intelligence: A Review</papertitle></a><br>
              Ruohan Zhang, <b>Akanksha Saran</b>, Bo Liu, Yifeng Zhu, Sihang Guo, Scott Niekum, Dana H. Ballard, <br>Mary M. Hayhoe<br>
              IJCAI 2020
              </p>
        
              <div class="paper" id="ijcai20">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="https://www.ijcai.org/Proceedings/2020/0689.pdf">pdf</a> 
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <!-- <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> | -->
              <!-- <a href="https://youtu.be/NsEvtSxxErQ">demo video</a> -->
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>A survey paper summarizing gaze-related research in computer vision, natural language processing, decision learning, and
                robotics in recent years.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/gaze2a.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://arxiv.org/abs/1907.07202v4" id="CoRL19">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Understanding Teacher Gaze Patterns for Robot Learning</papertitle></a><br>
              <b>Akanksha Saran</b>, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum
              <br>Short version: HRI Pioneers 2019
              <br>Full version: CoRL 2019
              </p>
        
              <div class="paper" id="icra21">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="https://arxiv.org/pdf/1907.07202v4.pdf">pdf</a> |
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <a href="https://github.com/asaran/gaze-LfD">code</a> |
              <a href="https://docs.google.com/presentation/d/1UG1iaLKOIfBkvDsjFbHnpo-gOR6LeFdW/edit?usp=sharing&ouid=108019005608041300274&rtpof=true&sd=true">slides</a> |
              <a href="posters/corl2019_poster.pdf">poster</a> |
              <a href="https://youtu.be/b7StSnt85S4?t=12240">talk video</a> |
              <a href="https://www.youtube.com/watch?v=FiCJRD-YluQ">demo video</a>
              
              <!-- <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre> -->
              </div>
              <!-- <p>Human teachers demonstrating goal-oriented manipulation tasks to robots fixate more of their eye gaze movements on objects important for the manipulation in comparison to other objects in the scene. Incorporating this finding during subtask classification and bayesian inverse reinforcement learning improves performance of these learning algorithms.</p> -->
              <p>Incorporating eye gaze information of human teachers demonstrating goal-oriented manipulation tasks to robots improves perfomance of subtask classification and bayesian inverse reinforcement learning.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/gaze_follow.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="papers/iros2018.pdf" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Human Gaze Following for Human-Robot Interaction</papertitle></a><br>
              <b>Akanksha Saran</b>, Srinjoy Majumdar, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum
              <br>Short version: Workshop on Social Robots in the Wild, HRI 2018
              <br>Full version: IROS 2018
              </p>
        
              <div class="paper" id="icra21">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="papers/iros2018.pdf">pdf</a> |
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <a href="https://github.com/Pearl-UTexas/gaze_tracker">code</a> |
              <a href="https://drive.google.com/file/d/1U6cEqJhFFj5Yq31o8LfOeibX-N8TRQug/view">talk video</a> |
              <a href="https://www.youtube.com/watch?v=zTZSpEcpW_A">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>An approach to predict human gaze fixations relevant for human-robot interaction tasks in real time from a robot's 2D camera view.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/viewpoint2.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="papers/iros2017.pdf" id="IROS17">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Viewpoint Selection for Visual Failure Detection</papertitle></a><br>
              <b>Akanksha Saran</b>, Branka Lakic, Srinjoy Majumdar, Juergen Hess, Scott Niekum
              <br>IROS 2017
              </p>
        
              <div class="paper" id="iros17">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="papers/iros2017.pdf">pdf</a> |
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('iros17')" class="togglebib">bibtex</a> | -->
              <!-- <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> | -->
              <a href="https://drive.google.com/file/d/1xVbWqnp0fQGa6W7Jc8xPYReAZ2RTQV8P/view?usp=sharing">slides</a> |
              <a href="https://drive.google.com/file/d/1ORHby7ivWtQdoI2lFLyocvLfFu-MMcHa/view?usp=sharing">spotlight</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>An approach to select a viewpoint (from a set of fixed viewpoints) to visually verify fine-grained task outcomes post robot task executions.</p>
            </td>
          </tr> 

         
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/hands.jpeg"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="papers/iros2015.pdf" id="IROS15">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Hand Parsing for Fine-Grained Recognition of Human Grasps in Monocular Images</papertitle></a><br>
              <b>Akanksha Saran</b>, Damien Teney, Kris Kitani
              <br>IROS 2015
              </p>
        
              <div class="paper" id="iros15">
              <!-- <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> | -->
              <a href="papers/iros2015.pdf">pdf</a> 
              <!-- <a href="javascript:toggleblock('icra21_abs')">abstract</a> | -->
              <!-- <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> | -->
              <!-- <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> | -->
              <!-- <a href="">slides</a> -->
              
              <!-- <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre> -->
              </div>
              <p>A data-driven approach for fine-grained grasp classification.</p>
            </td>
          </tr>   


        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Modified version of template from <a style="font-size:small;" href="https://jonbarron.info/">this</a> and <a href="https://www.cs.cmu.edu/~dpathak/">this</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
