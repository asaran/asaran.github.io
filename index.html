<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akanksha Saran</title>
  
  <!--<meta name="author" content="Akanksha Saran">-->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ut-icon.png"> <!--TODO: Replace UT icon-->

  <style>
    :root {
      --container: 800px; /* smaller container for bio and news*/
      --container-wide: 960px; /* bigger container for research*/
    }

    .container {
      max-width: var(--container);
    }

    .container-wide {
      max-width: var(--container-wide);
    }
  </style>
</head>

<body>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table class="container" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akanksha Saran</name>
              </p>
              <p> I am a PhD candidate in the Department of Computer Science at the University of Texas at Austin where I'm advised by <a href="https://www.cs.utexas.edu/~sniekum/">Prof. Scott Niekum</a>. 
                My interests lie at the intersection of Imitation Learning and Human Behavior Modeling. Specifically, 
                my research models intentions of human teachers using additional signals such as eye gaze and audio, for improved robot learning from demonstration.
              </p>
              <!--<p>Before coming to UT Austin, I worked for a short while as a Research Associate at the Robotics Institute, Carnegie Mellon University (CMU). Prior to that, I completed my MS in Robotics from CMU where, along with a team of computer vision, medical and design experts, I worked on developing a prototype for a <a href="https://smartrehab.vtc.vt.edu" >home-based stroke rehabilitation system</a>. Before pursuing graduate studies, I completed my undergraduate degree in Computer Science and Engineering from the Indian Institute of Technology, Jodhpur in India.
              </p>-->
              <p style="text-align:center">
                <a href="mailto:asaran@cs.utexas.edu">Email</a> &nbsp/&nbsp
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=zZhWSQ0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akanksha-saran/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/AkankshaSaran">Twitter</a> <!--&nbsp/&nbsp
                <a href="https://github.com/asaran/">Github</a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/akanksha4.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/akanksha4.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <hr class="container"/>

        <table class="container" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr><td>
            <heading>&nbsp;&nbsp;News</heading>
            <ul>
            <li> Our work <a href="papers/aux_airl.pdf">Aux-AIRL: End-to-End Self-Supervised Reward Learning for Extrapolating beyond Suboptimal Demonstrations</a> has been accepted to the <a href="https://icml21ssl.github.io">Workshop on Self-Supervised Learning for Reasoning and Perception</a> at <a href="https://icml.cc/">ICML 2021</a>.</li>
            <li> Invited talk at <a href="https://research.google">Google Research</a>.</li> 
            <li> Invited talk at <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a>.</li>
            <li> Invited talk at <a href="https://www.research.ibm.com/labs/watson/">IBM Research</a>.</li>
            <li> Invited talk at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>.</li>
            <li> Presented our work on <a href="https://arxiv.org/abs/2002.12500">Efficiently Guiding Imitation Learning Agents with Human Gaze</a> during the Humans and AI session at <a href="https://aamas2021.soton.ac.uk/">AAMAS 2021</a>.</li>
            <li> Invited talk at the <a href="https://sites.google.com/view/realworldhri-workshop/hri21/speakers-schedules?authuser=0">Workshop on Solutions for Socially Intelligent HRI in Real-World Scenarios</a> at <a href="https://humanrobotinteraction.org/2021/">HRI 2021</a>.</li>
            <li> I served as Program Chair for the <a href="http://www.hripioneers.info/hri21/program_speakers.html">HRI Pioneers workshop</a> at <a href="https://humanrobotinteraction.org/2021/">HRI 2021</a>.</li>
            <!--<a href="javascript:toggleblock('news')">---- show more ----</a>
            <div id="news" style="display:none">
            <li> Co-organized the <a href="https://futurecv.github.io/" target="_blank">"Computer Vision After 5 years"</a> workshop at CVPR'19.</li>
            <li> Co-organized the <a href="https://tarl2019.github.io/" target="_blank">Task Agnostic Reinforcement Learning</a> workshop at ICLR'19.</li>
            -->
          </div>
            <!-- <li> Undergrad <a href="#JPM15">paper</a> related to predicting <a href="http://www.huffingtonpost.co.uk/2015/02/23/microsoft-oscar-predictio_n_6735122.html">Oscars</a> published at <a href="http://ubplj.org/index.php/jpm/article/view/1048">JPM</a>. See <a href="#oscarPred">live predictions</a>.</li> -->
            </ul>
          </td></tr>
        </table>


        <hr class="container-wide"/>

        <table class="container" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>

            </td>
          </tr>
        </tbody></table>
        <style>

        /* image style format*/  
        .research-table img {
          display: block;
          max-width: 100%;
          height: auto;
          margin: 0 auto;  /*center align*/
          /* margin-left: auto; */ /*right align*/
        }
        </style>
        <table class="research-table container-wide"  style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            

          <tr>
            <!--Update the width:30% and width:70% for text and images to the required proportions-->
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div>
                <img src="images/aux_airl.png" />
              </div>
            </td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Aux-AIRL: End-to-End Self-Supervised Reward Learning for Extrapolating beyond Suboptimal Demonstrations</papertitle></a><br>
              Yuchen Cui, Bo Liu, <b>Akanksha Saran</b>, Stephen Giguere, Peter Stone, Scott Niekum<br>
              Short version: Workshop on Self-Supervised Learning for Reasoning <br>and Perception, ICML 2021
              <!-- <b>(Best Cognitive Robotics Paper Award Finalist)</b> -->
              </a>
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 

         

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/gaze3a.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Efficiently Guiding Imitation Learning Agents with Human Gaze</papertitle></a><br>
              <b>Akanksha Saran</b>, Ruohan Zhang, Elaine Schaertl Short, Scott Niekum<br>
              Short version: Workshop on Reinforcement Learning in Games, AAAI 2020
              <br>Full version: AAMAS 2021
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/survey.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Human Gaze Assisted Artificial Intelligence: A Review</papertitle></a><br>
              Ruohan Zhang, <b>Akanksha Saran</b>, Bo Liu, Yifeng Zhu, Sihang Guo, <br>Scott Niekum, Dana H. Ballard, Mary M. Hayhoe<br>
              IJCAI 2020
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/gaze2a.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Understanding Teacher Gaze Patterns for Robot Learning</papertitle></a><br>
              <b>Akanksha Saran</b>, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum
              <br>Short version: HRI Pioneers 2019
              <br>Full version: CoRL 2019
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/gaze1a.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Human Gaze Following for Human-Robot Interaction</papertitle></a><br>
              <b>Akanksha Saran</b>, Srinjoy Majumdar, Elaine Schaertl Short, Andrea Thomaz, Scott Niekum
              <br>Short version: Workshop on Social Robots in the Wild, HRI 2018
              <br>Full version: IROS 2018
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 




          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/viewpoint2.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Viewpoint Selection for Visual Failure Detection</papertitle></a><br>
              <b>Akanksha Saran</b>, Branka Lakic, Srinjoy Majumdar, Juergen Hess, Scott Niekum
              <br>IROS 2017
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> 

         
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
            <img src="images/hands.png"></a></td>
            <!-- <td width="67%" valign="top"> -->
              <td style="padding:20px;width:70%;vertical-align:top">
              <p><a href="https://yuqingd.github.io/autotuned-sim2real/" id="ICRA21">
              <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
              <papertitle>Hand Parsing for Fine-Grained Recognition of Human Grasps in Monocular Images</papertitle></a><br>
              <b>Akanksha Saran</b>, Damien Teney, Kris Kitani
              <br>IROS 2015
              </p>
        
              <div class="paper" id="icra21">
              <a href="https://yuqingd.github.io/autotuned-sim2real/">webpage</a> |
              <a href="https://arxiv.org/pdf/2104.07662.pdf">pdf</a> |
              <a href="javascript:toggleblock('icra21_abs')">abstract</a> |
              <a shape="rect" href="javascript:togglebib('icra21')" class="togglebib">bibtex</a> |
              <a href="https://github.com/yuqingd/sim2real2sim_rad">code</a> |
              <a href="https://youtu.be/NsEvtSxxErQ">demo video</a>
              <!-- 
              <p align="justify"> <i id="icra21_abs">Policies trained in simulation often fail when transferred to the real world due to the 'reality gap' where the simulator is unable to sufficiently accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning system parameters of simulator to match the real world using only raw observation images without the need to define rewards or estimate state in the real world itself. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over the conventional approach of domain randomization.</i></p>
        
        <pre xml:space="preserve">
        @article{du2021autotuned,
          author = {Du, Yuqing and
          Watkins, Olivia and
          Darrell, Trevor and Abbeel, Pieter
          and Pathak, Deepak},
          title  = {Auto-Tuned Sim-to-Real
          Transfer},
          journal= {ICRA},
          year   = {2021}
        }
        </pre>-->
              </div>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr>   


        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                
                Modified version of template from <a style="font-size:small;" href="https://jonbarron.info/">this</a> and <a href="https://www.cs.cmu.edu/~dpathak/">this</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
